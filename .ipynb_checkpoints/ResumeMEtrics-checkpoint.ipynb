{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fed7990-be37-47dc-9b3d-7c793564c084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved to: C:\\Users\\adity\\BE Project\\Stage4\\CandidateMetrics_Folder\\candidate_ranking_metrics.csv using config scoring.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# === Create output folder ===\n",
    "metrics_output_folder = Path(\"CandidateMetrics_Folder\")\n",
    "metrics_output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define full path to output CSV\n",
    "metrics_csv_path = metrics_output_folder / \"candidate_ranking_metrics.csv\"\n",
    "\n",
    "# === Load resume summary ===\n",
    "df = pd.read_csv(\"Resume_Parsed_CSVs/resume_summary.csv\")\n",
    "\n",
    "# === Load scoring config ===\n",
    "with open(\"config/scoring_config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "weights = config[\"weights\"]\n",
    "norm_multiplier = config[\"normalize_multiplier\"]\n",
    "\n",
    "# === Scoring Functions ===\n",
    "\n",
    "def certificate_score(cert_str):\n",
    "    try:\n",
    "        certs = ast.literal_eval(cert_str)\n",
    "        return len(certs) if isinstance(certs, list) else 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def project_score(projects_str):\n",
    "    try:\n",
    "        projects = ast.literal_eval(projects_str)\n",
    "        return 5 * sum(1 for p in projects if isinstance(p, dict) and p.get(\"Relevance to JD\", \"\").strip().lower() == \"high\")\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def skill_score(row):\n",
    "    match = config[\"skill_rules\"][\"match\"]\n",
    "    missing = config[\"skill_rules\"][\"missing\"]\n",
    "    try:\n",
    "        matched = ast.literal_eval(str(row[\"Top Matching Keywords\"]))\n",
    "        matched_count = len(matched)\n",
    "    except:\n",
    "        matched_count = 0\n",
    "    try:\n",
    "        missing_dict = ast.literal_eval(str(row[\"Missing Keywords\"]))\n",
    "        missing_count = sum(len(v) for v in missing_dict.values())\n",
    "    except:\n",
    "        missing_count = 0\n",
    "    return round((match * matched_count) + (missing * missing_count), 2)\n",
    "\n",
    "def contribute_score(contrib_str):\n",
    "    try:\n",
    "        skills = ast.literal_eval(contrib_str)\n",
    "        return 3 * len(skills) if isinstance(skills, list) else 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def soft_skill_score(soft_str):\n",
    "    try:\n",
    "        skills = ast.literal_eval(soft_str)\n",
    "        return 2 * len(skills) if isinstance(skills, list) else 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def industry_penalty(industry_str):\n",
    "    if isinstance(industry_str, str):\n",
    "        industry = industry_str.strip().lower()\n",
    "        if any(term in industry for term in [\"tech\", \"technology\", \"it\", \"cs\", \"computer\"]):\n",
    "            return 0\n",
    "    return -0.25\n",
    "\n",
    "def culture_score(fit_str):\n",
    "    if isinstance(fit_str, str):\n",
    "        return config[\"culture_fit_score\"].get(fit_str.strip().lower(), 0)\n",
    "    return 0\n",
    "\n",
    "def effort_score(effort_str):\n",
    "    if isinstance(effort_str, str):\n",
    "        return config[\"effort_needed_score\"].get(effort_str.strip().lower(), 0)\n",
    "    return 0\n",
    "\n",
    "def penalty_score(row):\n",
    "    gap = str(row[\"Employment Gaps Detected\"]).strip().lower() == \"true\"\n",
    "    gap_penalty = -5 if gap else 0\n",
    "    try:\n",
    "        red_flags = ast.literal_eval(row[\"Red Flags & Risk Analysis\"])\n",
    "        red_penalty = -0.5 * len(red_flags) if isinstance(red_flags, list) else 0\n",
    "    except:\n",
    "        red_penalty = 0\n",
    "    try:\n",
    "        concerns = ast.literal_eval(row[\"Potential Concerns\"])\n",
    "        concern_penalty = -0.1 * len(concerns) if isinstance(concerns, list) else 0\n",
    "    except:\n",
    "        concern_penalty = 0\n",
    "    return round(gap_penalty + red_penalty + concern_penalty, 2)\n",
    "\n",
    "def jd_match_score(jd_str):\n",
    "    try:\n",
    "        return float(jd_str.strip('%')) / 10\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def experience_score(exp_str):\n",
    "    try:\n",
    "        exp = float(exp_str)\n",
    "        thresholds = config[\"experience_score\"][\"thresholds\"]\n",
    "        scores = config[\"experience_score\"][\"scores\"]\n",
    "        if exp > thresholds[1]: return scores[2]\n",
    "        elif exp > thresholds[0]: return scores[1]\n",
    "        else: return scores[0]\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def candidate_type_score(type_str):\n",
    "    if isinstance(type_str, str):\n",
    "        level = type_str.strip().lower()\n",
    "        return config[\"candidate_type_score\"].get(level, 0)\n",
    "    return 0\n",
    "\n",
    "# === Insert Raw Score Columns ===\n",
    "\n",
    "df.insert(df.columns.get_loc(\"JD Match\") + 1, \"JD Match Score\", df[\"JD Match\"].apply(jd_match_score))\n",
    "df.insert(df.columns.get_loc(\"Relevant Experience (yrs)\") + 1, \"Experience Score\", df[\"Relevant Experience (yrs)\"].apply(experience_score))\n",
    "df.insert(df.columns.get_loc(\"Candidate Type\") + 1, \"Candidate Type Score\", df[\"Candidate Type\"].apply(candidate_type_score))\n",
    "df.insert(df.columns.get_loc(\"Projects\") + 1, \"Project Score\", df[\"Projects\"].apply(project_score))\n",
    "df.insert(df.columns.get_loc(\"Certifications & Courses\") + 1, \"Certificate Score\", df[\"Certifications & Courses\"].apply(certificate_score))\n",
    "df.insert(df.columns.get_loc(\"Top Matching Keywords\") + 1, \"Skill Score\", df.apply(skill_score, axis=1))\n",
    "df.insert(df.columns.get_loc(\"Skills That Will Contribute to the Company\") + 1, \"Contribute Score\", df[\"Skills That Will Contribute to the Company\"].apply(contribute_score))\n",
    "df.insert(df.columns.get_loc(\"Soft Skills & Leadership Qualities\") + 1, \"Soft Skill Score\", df[\"Soft Skills & Leadership Qualities\"].apply(soft_skill_score))\n",
    "df.insert(df.columns.get_loc(\"Industry Experience\") + 1, \"Industry Penalty\", df[\"Industry Experience\"].apply(industry_penalty))\n",
    "df.insert(df.columns.get_loc(\"Culture Fit Assessment\") + 1, \"Cultural Fit Score\", df[\"Culture Fit Assessment\"].apply(culture_score))\n",
    "df.insert(df.columns.get_loc(\"Effort Needed by the Company\") + 1, \"Effort Score\", df[\"Effort Needed by the Company\"].apply(effort_score))\n",
    "df.insert(df.columns.get_loc(\"Employment Gaps Detected\") + 1, \"Penalty Score\", df.apply(penalty_score, axis=1))\n",
    "\n",
    "# === Normalize Scores & Multiply ===\n",
    "\n",
    "score_columns = list(weights.keys())\n",
    "for col in score_columns:\n",
    "    min_val = df[col].min()\n",
    "    max_val = df[col].max()\n",
    "    norm_col = f\"Norm {col}\"\n",
    "    if max_val != min_val:\n",
    "        norm_vals = (df[col] - min_val) / (max_val - min_val)\n",
    "    else:\n",
    "        norm_vals = pd.Series([0.0] * len(df), index=df.index)\n",
    "    df.insert(df.columns.get_loc(col) + 1, norm_col, (norm_vals * norm_multiplier).round(2))\n",
    "\n",
    "# === Weighted Normalized Score and Rank ===\n",
    "\n",
    "df[\"Normalized Weighted Score\"] = sum(\n",
    "    df[f\"Norm {col}\"] * wt for col, wt in weights.items()\n",
    ").round(2)\n",
    "\n",
    "df[\"Normalized Rank\"] = df[\"Normalized Weighted Score\"].rank(method=\"dense\", ascending=False).astype(int)\n",
    "\n",
    "# === Save to CandidateMetrics_Folder ===\n",
    "\n",
    "df.to_csv(metrics_csv_path, index=False)\n",
    "print(f\"✅ Saved to: {metrics_csv_path.resolve()} using config scoring.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9094ee6-b1dc-4268-8e24-030a1efef5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bce1ee4-cd45-4213-a4cb-63ed9b1d4083",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
